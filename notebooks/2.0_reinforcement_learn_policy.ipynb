{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement learning the active learning policy \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import src.active_learning as al\n",
    "import src.viz as viz\n",
    "\n",
    "import importlib as imp\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.distributions import Categorical\n",
    "# import pyro\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data:\n",
    "\n",
    "Get MNIST formatted from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw datasets \n",
    "train_set = dset.MNIST(root='./data', train=True, transform=transforms.ToTensor(),download=False)\n",
    "test_set = dset.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=len(test_set),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x/y split for the test set \n",
    "train_x, train_y, val_x, val_y = al.get_dataset_split(train_set)\n",
    "test_x,test_y = al.get_xy_split(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the models:\n",
    "\n",
    "Below we make both the logistic regression and the CNN for experiemnts with RL on active learning policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "class logreg(nn.Module):\n",
    "    \"\"\" Logistic regression \"\"\"\n",
    "    def __init__(self, classes):\n",
    "        super(logreg, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.w = nn.Linear(28*28,classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.w(x.view(-1,1,28*28))\n",
    "        return F.log_softmax(x.view(-1,self.classes),dim=1)\n",
    "\n",
    "# Define the CNN model \n",
    "class CNN(nn.Module):\n",
    "    \"\"\" CNN for MNIST \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,1,28,28)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_policy(policy, meta_epochs, ept, npoints, batch_size, learning_rate, samp_runs):\n",
    "    # general policy test \n",
    "    try_acc = []\n",
    "    for i in tqdm(range(samp_runs)):\n",
    "        model_try = logreg(classes=10)\n",
    "#         model_try = CNN()\n",
    "        loss_try = nn.NLLLoss()\n",
    "        optimizer_try = optim.SGD(model_try.parameters(), lr=learning_rate)\n",
    "        experi = al.ExperiAL(model_try, train_x, train_y, val_x, val_y, loss_try, optimizer_try)\n",
    "        _, val_acc = experi.active_learn(policy=policy, epochs_per_train=ept, npoints=npoints, \\\n",
    "                                            batch_size=batch_size, meta_epochs=meta_epochs)\n",
    "        try_acc.append(val_acc)\n",
    "    print(f'Active Learning with {policy} policy done!')\n",
    "    return try_acc\n",
    "\n",
    "# model = logreg(classes=10)\n",
    "# loss_func = nn.NLLLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=.01)\n",
    "# experiment = al.ExperiAL(model, train_x, train_y, val_x, val_y, loss_func, optimizer)\n",
    "# experiment.active_learn(policy='boundary', meta_epochs=5, epochs_per_train=5, npoints=20, batch_size=10)\n",
    "\n",
    "# accs = [random_acc,boundary_acc,entropy_acc, confidence_acc,uniform_acc]\n",
    "# sample_acc = [a[-1][-1] for a in accs]\n",
    "# labs = ['Random','Boundary','Max Entropy', 'Least Confidence','Uniform']\n",
    "# nice_labs = [lab+f' {a}' for lab,a in zip(labs,sample_acc)]\n",
    "# viz.plot_results(meta_epochs,accs,nice_labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL approach - Policy Gradients (PG)\n",
    "\n",
    "* Source: http://karpathy.github.io/2016/05/31/rl/\n",
    "\n",
    "Here I will try the PG appraoch to this problem.\n",
    "\n",
    "##### Ideas:\n",
    "\n",
    "* actions are choosing the policy by which we choose the next point. \n",
    "\n",
    "* so is the state the performance of the model or the model itself or the parameters?? \n",
    "\n",
    "* OR IS THE STATE THE SET OF UNLABELED POINTS?!?!\n",
    "\n",
    "* State is the set of all training points \n",
    "\n",
    "* NO state should be the marginals $p(\\mathbf{y}|x_i)$ for real!!!\n",
    "\n",
    "* could use grad of accuracy to approx reward function. steeper the gradient higher the reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the RL agent to interact with the environment \n",
    "class AgentRL(nn.Module):\n",
    "    def __init__(self, inpt_dim, hidden_dim, num_policies):\n",
    "        super(AgentRL, self).__init__()\n",
    "        self.num_policies = num_policies\n",
    "        self.inner_layer = nn.Linear(inpt_dim, hidden_dim)\n",
    "        self.outer_layer = nn.Linear(hidden_dim, num_policies)\n",
    "        self.rewards = []\n",
    "        self.saved_log_probs = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.inner_layer(x))\n",
    "        x = self.outer_layer(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "def select_action(rl_agent, state):\n",
    "#     state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    if use_cuda:\n",
    "        probs = rl_agent(Variable(state.cuda()))\n",
    "    else:\n",
    "        probs = rl_agent(Variable(state))\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    rl_agent.saved_log_probs.append(m.log_prob(action))\n",
    "    return action.data[0]\n",
    "\n",
    "arl = AgentRL(4, 128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One RL approach (DQN):\n",
    "\n",
    "This is currently not working but could be good to try after policy gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch acc 0.8274\n",
      "OrderedDict([('w.weight', \n",
      "-3.0095e-02 -4.3774e-03 -1.1128e-02  ...  -1.8133e-02  1.5993e-02 -6.1285e-03\n",
      "-1.1412e-03  1.1096e-02 -3.4081e-02  ...  -1.3653e-02 -2.1021e-02  6.1761e-03\n",
      "-2.7035e-02  3.1876e-02  2.7182e-02  ...  -2.4003e-02 -3.5375e-02  3.4048e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 2.9983e-03  1.9402e-03  2.5775e-02  ...   2.1912e-02 -3.3439e-02  1.1415e-02\n",
      "-2.7456e-02 -3.3077e-04 -2.6443e-02  ...  -2.8893e-02  2.0001e-02  9.3709e-03\n",
      "-9.9710e-03  1.2108e-02 -3.2164e-02  ...   2.9064e-02 -1.2496e-02 -1.7155e-02\n",
      "[torch.FloatTensor of size 10x784]\n",
      "), ('w.bias', \n",
      "1.00000e-02 *\n",
      " -6.5094\n",
      "  9.2180\n",
      " -3.3772\n",
      "  0.2998\n",
      "  1.2790\n",
      "  4.2864\n",
      "  0.2122\n",
      "  4.4110\n",
      " -4.8635\n",
      " -2.7203\n",
      "[torch.FloatTensor of size 10]\n",
      ")])\n",
      "OrderedDict([('w.weight', \n",
      "-0.0301 -0.0044 -0.0111  ...  -0.0181  0.0160 -0.0061\n",
      "-0.0011  0.0111 -0.0341  ...  -0.0137 -0.0210  0.0062\n",
      "-0.0270  0.0319  0.0272  ...  -0.0240 -0.0354  0.0340\n",
      "          ...             ⋱             ...          \n",
      " 0.0030  0.0019  0.0258  ...   0.0219 -0.0334  0.0114\n",
      "-0.0275 -0.0003 -0.0264  ...  -0.0289  0.0200  0.0094\n",
      "-0.0100  0.0121 -0.0322  ...   0.0291 -0.0125 -0.0172\n",
      "[torch.FloatTensor of size 10x784]\n",
      "), ('w.bias', \n",
      "-0.1436\n",
      " 0.2338\n",
      "-0.0532\n",
      "-0.0720\n",
      " 0.0591\n",
      " 0.3171\n",
      "-0.0126\n",
      " 0.1885\n",
      "-0.4132\n",
      "-0.0815\n",
      "[torch.FloatTensor of size 10]\n",
      ")])\n",
      "20 epoch acc 0.8958\n",
      "OrderedDict([('w.weight', \n",
      "-0.0301 -0.0044 -0.0111  ...  -0.0181  0.0160 -0.0061\n",
      "-0.0011  0.0111 -0.0341  ...  -0.0137 -0.0210  0.0062\n",
      "-0.0270  0.0319  0.0272  ...  -0.0240 -0.0354  0.0340\n",
      "          ...             ⋱             ...          \n",
      " 0.0030  0.0019  0.0258  ...   0.0219 -0.0334  0.0114\n",
      "-0.0275 -0.0003 -0.0264  ...  -0.0289  0.0200  0.0094\n",
      "-0.0100  0.0121 -0.0322  ...   0.0291 -0.0125 -0.0172\n",
      "[torch.FloatTensor of size 10x784]\n",
      "), ('w.bias', \n",
      "-0.1436\n",
      " 0.2338\n",
      "-0.0532\n",
      "-0.0720\n",
      " 0.0591\n",
      " 0.3171\n",
      "-0.0126\n",
      " 0.1885\n",
      "-0.4132\n",
      "-0.0815\n",
      "[torch.FloatTensor of size 10]\n",
      ")])\n",
      "should be 5 epoch acc 0.8958\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b50ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "model = logreg(classes=10)\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.01)\n",
    "experiment = al.ExperiAL(model, train_x, train_y, val_x, val_y, loss_func, optimizer)\n",
    "it,ac = experiment._train(train_x, train_y, epochs=1, batch_size=128)\n",
    "\n",
    "plt.plot(it,ac)\n",
    "sd = model.state_dict()\n",
    "print('1 epoch acc',al.accuracy(model,val_x,val_y))\n",
    "print(sd)\n",
    "it,ac = experiment._train(train_x, train_y, epochs=15, batch_size=128)\n",
    "plt.plot(it,ac)\n",
    "sd2 = model.state_dict()\n",
    "print(sd2)\n",
    "print('20 epoch acc',al.accuracy(model,val_x,val_y))\n",
    "print(sd)\n",
    "model.load_state_dict(sd)\n",
    "model.state_dict()\n",
    "print('should be 5 epoch acc',al.accuracy(model,val_x,val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8 6 5 5 3 4 7]\n",
      "[2 3 5 4 7 6 8 5]\n",
      "[5 8 5 2 7 6 4 3]\n",
      "[4 5 2 6 7 8 3 5]\n",
      "[5 6 2 5 4 8 3 7]\n",
      "[6 5 4 2 5 7 3 8]\n",
      "[8 5 2 4 7 3 5 6]\n",
      "[5 3 5 7 4 8 2 6]\n"
     ]
    }
   ],
   "source": [
    "preds = [5,5,6,7,8,4,3,2]\n",
    "num_points, sampler = len(preds), np.array(range(len(preds)))\n",
    "# output = []\n",
    "for i in range(num_points):\n",
    "    print(np.random.choice(preds, size=num_points, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
